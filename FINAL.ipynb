{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:49:08.174519Z",
     "start_time": "2020-03-31T13:49:08.165989Z"
    },
    "colab_type": "text",
    "id": "G2G9R-pQvKbr"
   },
   "source": [
    "# Tarea 1 NLP : Competencia de Clasificación de Texto\n",
    "-------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCrkqG4JvKbz"
   },
   "source": [
    "- **Nombres:** Valentina Sepulveda, Joaquín Pérez\n",
    "\n",
    "- **Usuario o nombre de equipo en Codalab:** meperd0nas, vsepulv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T14:34:38.796217Z",
     "start_time": "2020-04-07T14:34:38.782255Z"
    },
    "colab_type": "text",
    "id": "7h1JBoHEvKcI"
   },
   "source": [
    "### Detalles e instrucciones de la competencia:\n",
    "\n",
    "- La competencia consiste en resolver 4 problemas de clasificación distintos, cada uno de tres clases. Por cada problema deberán crear un clasificador distinto. La evaluación de la competencia se realiza en base a 4 métricas: AUC, Kappa y Accuracy. Los mejores puntajes en cada ítem serán los que ganen.\n",
    "\n",
    "- Para comenzar se les entregará en este notebook el baseline y la estructura del reporte. El baseline es el código que realiza creación de features y clasificación básica. Los puntajes de este serán ocupados como base para la competencia: deben superar sus resultados para ser bien evaluados.  \n",
    "\n",
    "- Para participar, deben registrarse en Codalab y luego ingresar a la competencia usando el siguiente [link]( https://competitions.codalab.org/competitions/24121?secret_key=f5eb2d95-b36e-4aad-8fc5-4d9d77f4e4dc). \n",
    "\n",
    "- **Es requisito entregar el reporte con el código y haber participado en la competencia para ser evaluado.**\n",
    "\n",
    "- Pueden hacer grupos de máximo 2 alumnos. Cada grupo debe tener un nombre de equipo (En codalab, ir a settings y después cambiar Team Name). Solo una persona debe administrar la cuenta del grupo.\n",
    "\n",
    "- En total pueden hacer un **máximo de 4 envíos/submissions** (tanto para equipos como para envíos indivuales).\n",
    "\n",
    "- Hagan varios experimentos haciendo cross-validation o evaluación sobre una sub-partición antes de enviar sus predicciones a Codalab. Asegúrense que la distribución de las clases sea balanceada en las particiones de training y testing. Verificar que el formato de la submission coincida con el de la competencia. De lo contrario, se les será evaluado incorrectamente.\n",
    "\n",
    "- Estar top 5 en alguna métrica equivale a 1 punto extra en la nota final.\n",
    "\n",
    "- No se limiten a los contenidos vistos ni a scikit ni a este baseline. ¡Usen todo su conocimiento e ingenio en mejorar sus sistemas! \n",
    "\n",
    "- Todas las dudas escríbanlas en el hilo de U-cursos de la tarea. Los emails que lleguen al equipo docente serán remitidos a ese medio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8W8H7JKvKcO"
   },
   "source": [
    "### Reporte\n",
    "\n",
    "Este debe cumplir la siguiente estructura:\n",
    "\n",
    "1.\t**Introducción**: Presentar brevemente el problema a resolver, los métodos y representaciones utilizadas en el desarrollo de la tarea y conclusiones obtenidas. (0.5 Puntos)\n",
    "2.\t**Representaciones**: Describir los atributos y representaciones usadas como entrada de los clasificadores. Si bien, con Bag of Words (baseline) ya se comienzan a percibir buenos resultados, pueden mejorar su evaluación agregando más atributos y representaciones diseñadas a mano. Mas abajo encontrarán una lista útil de estos que les podrá ser de utilidad. (1.5 puntos)\n",
    "3.\t**Algoritmos**: Describir brevemente los algoritmos de clasificación usados. (0.5 puntos)\n",
    "4.\t**Métricas de evaluación**: Describir brevemente las métricas utilizadas en la evaluación indicando que miden y su interpretación. (0.5 puntos)\n",
    "5.\t**Experimentos**: Reportar todos sus experimentos. Comparar los resultados obtenidos utilizando diferentes algoritmos y representaciones. Estos experimentos los hacen sobre la sub-partición de evaluación que deben crear (o pueden usar cross-validation). Incluyan todo el código de sus experimentos aquí. ¡Es vital haber realizado varios experimentos para sacar una buena nota! (2 puntos)\n",
    "6.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:18:43.301002Z",
     "start_time": "2019-08-21T19:18:43.298037Z"
    },
    "colab_type": "text",
    "id": "UQ53VkYdvKcU"
   },
   "source": [
    "### Baseline\n",
    "\n",
    "Por último, el baseline contiene un código básico que:\n",
    "\n",
    "- Obtiene los dataset.\n",
    "- Divide los datasets en train (entrenamiento y prueba) y target set (el que clasificar para subir a la competencia).\n",
    "- Crea un Pipeline que: \n",
    "    - Crea features personalizadas.\n",
    "    - Transforma los dataset a bag of words (BoW).  \n",
    "    - Entrena un clasificador usando cada train set.\n",
    "- Clasifica y evalua el sistema creado usando el test set.\n",
    "- Clasifica el target set.\n",
    "- Genera una submission con el target en formato zip en el directorio en donde se está ejecutando el notebook. \n",
    "\n",
    "Algunas pistas sobre como mejorar el rendimiento de los sistemas que creen. (Esto tendrá mas sentido cuando vean el código)\n",
    "\n",
    "- **Vectorizador**: investigar los modulos de `nltk`, en particular, `TweetTokenizer`, `mark_negation` para reemplazar los tokenizadores. También, el parámetro `ngram_range` (Ojo que el clf naive bayes no debería usarse con n-gramas, ya que rompe el supuesto de independencia). Además, implementar los atributos que crean útiles desde el listado del el enunciado. Investigar también el vectorizador tf-idf.\n",
    "\n",
    "- **Clasificador**: investigar otros clasificadores mas efectivos que naive bayes. Estos deben poder retornar la probabilidad de pertenecia de las clases (ie: implementar la función `predict_proba`).\n",
    "\n",
    "- **Features**: Recuerden que pueden implementar todas las features que se les ocurra! Aquí les adjuntamos algunos ejemplos:\n",
    "    -\tWord n-grams.\n",
    "    -\tCharacter n-grams. \n",
    "    -\tPart-of-speech tags.\n",
    "    -\tSentiment Lexicons (Lexicon = A set of words with a label or associated value.).\n",
    "        - Count the number of positive and negative words within a sentence.\n",
    "        - If the lexicon has associated intensity of feeling (for example in a decimal), then take the average of the intensity of the sentence according to the feeling, the sum, etc.\n",
    "        -\tA good lexicon of sentiment: [Bing Liu](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar) \n",
    "        - A reference with a lot of [sentiment lexicons](https://medium.com/@datamonsters/sentiment-analysis-tools-overview-part-1-positive-and-negative-words-databases-ae35431a470c). \n",
    "    -\tThe number of elongated words (words with one character repeated more than two times).\n",
    "    -\tThe number of words with all characters in uppercase.\n",
    "    -\tThe presence and the number of positive or negative emoticons.\n",
    "    -\tThe number of individual negations.\n",
    "    -\tThe number of contiguous sequences of dots, question marks and exclamation marks.\n",
    "    -\tWord Embeddings: Here are some good ideas on how to use them.\n",
    "    https://stats.stackexchange.com/questions/221715/apply-word-embeddings-to-entire-document-to-get-a-feature-vector\n",
    "\n",
    "- **Reducción de dimensionalidad**: También puede serles de ayuda. Referencias [aquí](https://scikit-learn.org/stable/modules/unsupervised_reduction.html).\n",
    "\n",
    "- Por último, pueden encontrar mas referencias de cómo mejorar sus features, el vectorizador y el clasificador [aquí](https://affectivetweets.cms.waikato.ac.nz/benchmark/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GGbVakLvKcn"
   },
   "source": [
    "----------------------------------------\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "La clasificación de emociones es una tema importante para encontrar patrones y relaciones que no son facilmente notadas por el ser humano pero que sin embargo son utilizadas diariamente, en particular calcular la intensidad de estas nos permite encontrar qué ciertos patrones dan más \"fuerza\" a una emoción dado el tipo de texto y el tipo de palabras usadas. Es dado esta importancia que es necesario resolver este problema. \n",
    "\n",
    "En este caso particular tenemos cuatro emociones distintas, alegria, tristeza, miedo y enojo, y tenemos varias intensidades asociadas a cada una de estas emociones que pueden ir de intensidad baja hasta intensidad alta. El problema a resolver es encontrar un clasificador que sea capaz de correctamente clasificar la intensidad de estas emociones dado unos tweet, para cada una de estas cuatro emociones. \n",
    "\n",
    "Para resolverlas se decidió entrenar un estimador con un set de entrenamiento y luego probarlo con un set de testeo. Para hacer este entrenamiento para el clasificador, se decidió que el clasificador tomaría los tweets y los veria como un bag of words de n-gramas, y que luego dado esta representacion se añadería por medio de transformaciones una serie de caracteristicas que serian del tipo Feature Vector, es decir vectores con valores que representarían una feature en particular y que describirian el tweet.\n",
    "\n",
    "Se decidió el uso de un algoritmo: la regresión lineal, en particular la regresión logística. Este algoritmo se decidió en base a que otorga una probabilidad y en base tambien a que otorgó el mejor resultado dado unas pruebas.\n",
    "\n",
    "Los experimentos que se decidieron hacerse fueron en base a distintos features y distintos algoritmos, uno probando con todos el mismo clasificador y mismas features, y otro con distintos features pero el mismo estimador. Estos primeros experimentos tuvieron *accuracy* de menos del sesenta por ciento por lo que se decidió analizar más a profundidad el codigo. Luego de analizarlo y modificar features para que tuvieran mayor peso, los resultados pasaron a más de setenta por ciento de accuracy promedio.\n",
    "\n",
    "Se concluyó que las features afectan enormente la precision del clasificador, pero tambien que la manera en que está escrito el codigo tambien afecta, puesto que al rescribirlo mejoró su puntaje de forma considerable. También se concluye que es necesario analizar el train input, puesto que al hacer una prueba con todas las mismas features el puntaje era desigual y este mejoró al hacer el clasificador más especializado.\n",
    "\n",
    "Dado proyectos futuros, faltaría mejorar la clasificación para la intensidad media puesta que esta tenia menor *accuracy* que la intensidad alta y baja en todas las emociones. Una idea sería hacer un clasificador intermedio que clasifique entre intensidad extrema, lease baja o alta, versus intensidad media. O buscar en otros algoritmos de clasificación que no fueron considerados anteriormente. Este clasificador podria utilizarse en el futuro para clasificar emociones dado un evento o ver la opinion del publico respecto a ciertos temas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías y utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "EXzxb-SpATDg",
    "outputId": "8b5ac5e7-d6ce-44b1-ff81-1dec36bf15ed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3184 | INFO | loading projection weights from C:\\Users\\Amitsuu/gensim-data\\glove-twitter-50\\glove-twitter-50.gz\n",
      "3184 | INFO | loaded (1193514, 50) matrix from C:\\Users\\Amitsuu/gensim-data\\glove-twitter-50\\glove-twitter-50.gz\n",
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     C:\\Users\\Amitsuu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import emojis\n",
    "except ImportError:\n",
    "    !pip install emojis\n",
    "    import emojis\n",
    "\n",
    "try:\n",
    "    import gensim.downloader as api\n",
    "except ImportError:\n",
    "    !pip install gensim\n",
    "    import gensim.downloader as api # https://github.com/RaRe-Technologies/gensim-data\n",
    "\n",
    "\n",
    "try:\n",
    "    from better_profanity import profanity\n",
    "except ImportError:\n",
    "    !pip install better_profanity\n",
    "    from better_profanity import profanity\n",
    "\n",
    "try:\n",
    "    from senticnet.senticnet import SenticNet\n",
    "except ImportError:\n",
    "    !pip install senticnet\n",
    "    from senticnet.senticnet import SenticNet\n",
    "\n",
    "try:\n",
    "    from emosent import get_emoji_sentiment_rank\n",
    "except ImportError:\n",
    "    !pip install emosent-py\n",
    "    from emosent import get_emoji_sentiment_rank\n",
    "    # NOTA: Si este paquete arroja un error de decode\n",
    "    # Hay que modificar el siguiente archivo en el ambiente:\n",
    "    # env/Lib/site-packages/emosent/emosent.py\n",
    "    # Hay que agregar un parámetro extra al open que está allí: encoding=\"utf8\"\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# get the model\n",
    "model = api.load(\"glove-twitter-50\")\n",
    "nltk.download('opinion_lexicon')\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.sentiment.util import mark_negation\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK3Srgqu_yTI"
   },
   "source": [
    "### Datos ####\n",
    "\n",
    "Los datos son los que son dados de la competencia. Consiste en 4 datasets de entrenamiento y 4 datasets de testeo. Un dataset para enojo, alegria, miedo y tristeza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FauIAEaMqBRS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Datasets de entrenamiento.\n",
    "train = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/anger-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/fear-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/joy-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/sadness-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'])\n",
    "}\n",
    "# Datasets que deberán predecir para la competencia.\n",
    "target = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/anger-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/fear-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/joy-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/sadness-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nyqmE30oCAxc"
   },
   "source": [
    "#### Balanceo de Clases ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 163    163    163\n",
      "low                  161    161    161\n",
      "medium               617    617    617 \n",
      "---------------------------------------\n",
      "\n",
      "fear \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 270    270    270\n",
      "low                  288    288    288\n",
      "medium               699    699    699 \n",
      "---------------------------------------\n",
      "\n",
      "joy \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 195    195    195\n",
      "low                  219    219    219\n",
      "medium               488    488    488 \n",
      "---------------------------------------\n",
      "\n",
      "sadness \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 197    197    197\n",
      "low                  210    210    210\n",
      "medium               453    453    453 \n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_group_dist(group_name, train):\n",
    "    print(group_name, \"\\n\",\n",
    "          train[group_name].groupby('sentiment_intensity').count(),\n",
    "          '\\n---------------------------------------\\n')\n",
    "for dataset_name in train:\n",
    "    get_group_dist(dataset_name, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los datos de entrenamiendo, se observa un desbalance de las muestras, ya que hay una mayor cantidad \n",
    " de datos clasificados `medium` en el corpus de entrenamiento. Por lo que se decidió realizar un\n",
    " balanceo haciendo undersampling de datos de categoría `medium`, hasta que fueran comparables con la cantidad de\n",
    " datos `low` y `high`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0aQopQlMCI9"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_resampled = {}\n",
    "for key in train:\n",
    "    df = train.get(key)\n",
    "    high=df['sentiment_intensity']=='high'\n",
    "    high=df[high]\n",
    "    med=df['sentiment_intensity']=='medium'\n",
    "    med=df[med]\n",
    "    low=df['sentiment_intensity']=='low'\n",
    "    low=df[low]\n",
    "    downsample_size = max(len(low), len(high)) # Se reescala hasta el mayor de los otros dos\n",
    "    med_re= resample(med, \n",
    "                replace=False,    # sample without replacement\n",
    "                n_samples=downsample_size,     # to match minority class\n",
    "                random_state=123) # reproducible results\n",
    "\n",
    "    df_resampled[key] = pd.concat([med_re, high, low])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPIcYA2IM8jt"
   },
   "source": [
    "## 2. Representaciones\n",
    "Para resolver el problema se decidió principalmente usar un Vector de n-gramas, junto con unas transformaciones en un Feature Vector. Este Feature Vector siendo definido a traves de varias caracteristicas que son explicadas más adelante, pero que principalmente consisten en el uso de palabras claves y su uso dentro de cada tweet.\n",
    "\n",
    "##### Tokenizador\n",
    "Para el tokenizador se utilizó `TweetTokenizer` de `nltk`, un tokenizador hecho a medida para tweets. Con este se divide el Tweet en una lista de strings, incluyendo los hashtags, y los emojis.\n",
    "\n",
    "##### HashTag Bonus y Mark_negation\n",
    "Para darle más peso a las palabras dentro de los hashtags se les agrega puntaje adicional a las palabras al ser dichas con #, dado que al usar un hashtag el usuario le\n",
    "está dando un énfasis extra a ésta palabra. Este puntaje adicional se aplica en los features `MoodScore`\n",
    "y en `SentimentLexicon`. Tambien en estas features se aplica `mark_negation` función que aplica\n",
    "un preprocesamiento a la oración para indicar las palabras negadas para que al momento de contalibizarlas\n",
    "se hagan de forma inversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_hashtag_bonus(score, hashtag):\n",
    "    if hashtag:\n",
    "        return score*6\n",
    "    else:\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Gramas\n",
    "Se utilizaron 4, 3, 2, 1-gramas de palabras, utilizando el tokenizador por defecto y `mark_negation`.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`, `Joy`, `Sadness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_tokenizer = TweetTokenizer()\n",
    "def n_gram_feature_neg():\n",
    "    return CountVectorizer(analyzer='word',\n",
    "                                    ngram_range=(1, 4),\n",
    "                                    tokenizer=t_tokenizer.tokenize,\n",
    "                                    preprocessor = mark_negation,\n",
    "                                    )\n",
    "\n",
    "def n_gram_feature():\n",
    "    return CountVectorizer(analyzer='word',\n",
    "                                    ngram_range=(1, 4),\n",
    "                                    tokenizer=t_tokenizer.tokenize,\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### EmojiCount\n",
    "Cuenta la cantidad de emojis que hay en un tweet. A los que posean más emojis se les agrega más puntaje, para aumentar la intensidad de la emoción al momento de representarlo.\n",
    "\n",
    "Utilizado en los clasificadores: `Joy`, `Sadness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EmojiCount(BaseEstimator, TransformerMixin):\n",
    "    # largo = 1\n",
    "    def get_relevant_chars(self, tweet):\n",
    "        num_emojis = emojis.count(tweet)**2\n",
    "        return [num_emojis]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        chars = []\n",
    "        for tweet in X:\n",
    "            chars.append(self.get_relevant_chars(tweet))\n",
    "        return np.array(chars)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CharsCount\n",
    "Cuenta la cantidad de carácteres especiales o strings especificos que hay en un tweet. Esta clase se inicializa en el pipeline de cada\n",
    "clasificador para contar carácteres en específico.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`, `Joy`, `Sadness`.\n",
    "\n",
    "Los strings específicos utilizados se encontraron, viendo el dataset. Notando la prevalencia de ciertas palabras clave\n",
    "para determinadas emociones:\n",
    "\n",
    "`sadness`:  `sad`, `depress`, `anxi`, `feel`, `!`, `gloo`, `..`\n",
    "\n",
    "`anger`: `angry`, `fuck`, `#`, `!`, `*`\n",
    "\n",
    "`fear`: `terr`, `..`, `feel`, `panic`, `anxi`, `nerv`\n",
    "\n",
    "`joy`: `lov`, `happy`, `joy`, `smil`, `❤`, `!`, `fun`, `laugh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CharsCount(BaseEstimator, TransformerMixin):\n",
    "    # largo = 1\n",
    "    def __init__(self, char):\n",
    "        self.char = char\n",
    "\n",
    "    def get_relevant_chars(self, tweet):\n",
    "        num_chars = 2**tweet.lower().count(self.char)\n",
    "        return [num_chars / len(tweet)]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        chars = []\n",
    "        for tweet in X:\n",
    "            chars.append(self.get_relevant_chars(tweet))\n",
    "\n",
    "        return np.array(chars)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoodScore:\n",
    "Este feature usa SenticNet para obtener los estados de ánimo asociados a cada palabra válida del Tweet,\n",
    "hay 8 estados de ánimo etiquetados por SenticNet: `sadness, disgust, joy, interest, admiration, anger, surprise ` y `fear`.\n",
    "Cada palabra válida contiene sólo dos estados anímicos, aumentando en 1 su conteo de estado anímico.\n",
    "Si la palabra está negada (usando `mark_negation`), el conteo se reduce en 1.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`, `Joy`, `Sadness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MoodScore(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, hashtag_scoring=False):\n",
    "        self.hashtag_scoring = hashtag_scoring\n",
    "    # largo = 8\n",
    "    def negate(self, number, boolean):\n",
    "        if boolean:\n",
    "            return -number\n",
    "        else:\n",
    "            return  number\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        sentiment_array=[]\n",
    "        sn = SenticNet()\n",
    "        for tweet in X:\n",
    "            moods = {\n",
    "                 '#sadness':0,\n",
    "                 '#disgust':0,\n",
    "                 '#joy':0,\n",
    "                 '#interest':0,\n",
    "                 '#admiration':0,\n",
    "                 '#anger':0,\n",
    "                 '#surprise':0,\n",
    "                 '#fear':0\n",
    "            }\n",
    "            mood_array = np.zeros(8)\n",
    "            tokenizer = TweetTokenizer()\n",
    "            tokens = tokenizer.tokenize(tweet)\n",
    "            tokens_neg = mark_negation(tokens)\n",
    "            for token in tokens_neg:\n",
    "                negated = False\n",
    "                hashtag = False\n",
    "                if token[-4:] == \"_NEG\":\n",
    "                    negated = True\n",
    "                    token = token[:-4]\n",
    "                if token[:1] == \"#\":\n",
    "                    token = token[1:]\n",
    "                    hashtag = True and self.hashtag_scoring\n",
    "                if token in sn.data:\n",
    "                    if sn.polarity_value(token) == 'positive':\n",
    "                        score = apply_hashtag_bonus(1, hashtag)\n",
    "                    else:\n",
    "                        score = apply_hashtag_bonus(-1, hashtag)\n",
    "                    for tag in sn.moodtags(token):\n",
    "                        moods[tag] += self.negate(score, negated)\n",
    "\n",
    "            for idx, key in enumerate(moods):\n",
    "                mood_array[idx] = moods[key]\n",
    "\n",
    "\n",
    "            sentiment_array.append(mood_array)\n",
    "\n",
    "        return np.array(sentiment_array)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordEmbeddings:\n",
    "Para los Word Embeddings se utilizó el WordEmbedding de GloveTwitter, se utilizó el modelo 50 de éste WE.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`, `Joy`, `Sadness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WordEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    # Usa el diccionario y encuentra su origen\n",
    "    def __init__(self, model):\n",
    "      self.model = model\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        aggregation = np.mean\n",
    "        tokenizer = TweetTokenizer()\n",
    "        doc_embeddings = []\n",
    "        for tweet in X:\n",
    "            tokens = tokenizer.tokenize(tweet)\n",
    "            selected_words = []\n",
    "            for token in tokens:\n",
    "                if token in self.model.vocab:\n",
    "                    selected_words.append(self.model[token])\n",
    "            \n",
    "            if len(selected_words) > 0:\n",
    "                doc_emb = aggregation(np.array(selected_words), axis = 0)\n",
    "                doc_embeddings.append(doc_emb)\n",
    "            else:\n",
    "                doc_embeddings.append(np.zeros(self.model.vector_size))\n",
    "\n",
    "        return np.array(doc_embeddings)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SentimentLexicon:\n",
    "Utiliza el `opinion_lexicon` de `nltk` para obtener la cantidad de palabras positivas y negativas de un Tweet. Si se encuentra una palabra positiva, aumenta el grado de \"positividad\" que tiene el tweet, por el contrario si se encuentra con una palabra de connotacion negativa este valor este aumenta su grado de \"negatividad\". Al final se entregan las palabras positivas y negativas del tweet.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`, `Joy`, `Sadness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "class SentimentLexicon(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, hashtag_scoring=False):\n",
    "        self.hashtag_scoring = hashtag_scoring\n",
    "\n",
    "    # largo = 2\n",
    "    def fun(self, tweet):\n",
    "        tokenizer = TweetTokenizer()\n",
    "        t=tokenizer.tokenize(tweet)\n",
    "        t = mark_negation(t)\n",
    "        pos_list=set(opinion_lexicon.positive())\n",
    "        neg_list=set(opinion_lexicon.negative())\n",
    "        pos_words=0\n",
    "        neg_words=0\n",
    "        for i in t:\n",
    "            negated = False\n",
    "            hashtag = False\n",
    "            if i[-4:] == \"_NEG\":\n",
    "                negated = True\n",
    "                i = i[:-4]\n",
    "            if i[:1] == \"#\":\n",
    "                i = i[1:]\n",
    "                hashtag = True and self.hashtag_scoring\n",
    "            if i in pos_list:\n",
    "                if negated:\n",
    "                    neg_words=neg_words+apply_hashtag_bonus(1,hashtag)\n",
    "                else:\n",
    "                    pos_words=pos_words+apply_hashtag_bonus(1,hashtag)\n",
    "            elif i in neg_list:\n",
    "                if negated:\n",
    "                    pos_words=pos_words+apply_hashtag_bonus(1,hashtag)\n",
    "                else:\n",
    "                    neg_words=neg_words+apply_hashtag_bonus(1,hashtag)\n",
    "        return [pos_words,neg_words]\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(self.fun(tweet))\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UpperLetters:\n",
    "Cuenta la tasa de mayusculas de un Tweet. Asi si un tweet tiene todos sus palabras en mayusculas, este tiene una tasa más grande y por ende una intensidad mayor de la emoción que intenta clasificar.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Joy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%     \n"
    }
   },
   "outputs": [],
   "source": [
    "class UpperLetters(BaseEstimator, TransformerMixin):\n",
    "    # largo = 1\n",
    "    def fun(self, tweet):\n",
    "        tokenizer=TweetTokenizer()\n",
    "        t=tokenizer.tokenize(tweet)\n",
    "        largo=len(t)\n",
    "        num_Upper=0\n",
    "        for i in t:\n",
    "            if i.isupper() and len(i)>1:\n",
    "                num_Upper=num_Upper+1\n",
    "        return [num_Upper/largo]\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(self.fun(tweet))\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### LowerLetters:\n",
    "Cuenta la tasa de mayusculas de un Tweet. Esto cuenta lo contrario a la Feature anterior, si hay un numero mayor de palabras en minusculas, aumenta la tasa y por ende aumenta la intensidad de emociones negativas como lo son la tristeza y el miedo.\n",
    "\n",
    "Utilizado en los clasificadores: `Fear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LowerLetters(BaseEstimator, TransformerMixin):\n",
    "    # largo = 1\n",
    "    def fun(self, tweet):\n",
    "        tokenizer=TweetTokenizer()\n",
    "        t=tokenizer.tokenize(tweet)\n",
    "        largo=len(t)\n",
    "        num_Lower=0\n",
    "        for i in t:\n",
    "            if i.islower() and len(i)>1:\n",
    "                num_Lower=num_Lower+1\n",
    "        return [num_Lower/largo]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(self.fun(tweet))\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CurseWords:\n",
    "Utilizando el paquete `better_profanity`, cuenta la cantidad de palabras ofensivas. Mientras más *curse words* hay, aumenta la intensidad de la emoción.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CurseWords(BaseEstimator, TransformerMixin):\n",
    "    # largo = 1\n",
    "    def countCurseWords(self, tweet):\n",
    "        t=TweetTokenizer().tokenize(tweet)\n",
    "        x=0\n",
    "        for i in t:\n",
    "            if profanity.contains_profanity(i):\n",
    "                x=x+1\n",
    "        return [x*10]\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(self.countCurseWords(tweet))\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### EmojiScore:\n",
    "\n",
    "Utilizando el paquete `emosent-py`, obtiene los puntajes de sentimiento de cada uno de los emojis del tweet, que tiene un puntaje positivo, neutro y negativo asociado. Así las emociones como alegria tienen una carga más positiva mientras que emociones como tristeza tiene una carga más negativa.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`, `Joy`, `Sadness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EmojiScore(BaseEstimator, TransformerMixin):\n",
    "    # largo = 3\n",
    "    def fun(self, tweet):\n",
    "        tokenizer = TweetTokenizer()\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        neutral = 0\n",
    "        for token in tokens:\n",
    "            try: # Horrible forma de saber si un token es un emoji :c\n",
    "                # y hay emojis que no tienen datos en esta libreria\n",
    "                data = get_emoji_sentiment_rank(token)\n",
    "                positive += data.get('positive')\n",
    "                negative += data.get('negative')\n",
    "                neutral += data.get('neutral')\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        return [positive, neutral, negative]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(self.fun(tweet))\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emoticons:\n",
    "Cuenta las caritas que se pueden hacer utilizando sólo ASCII. Dependiendo del tipo de emoticons, se le asocia una emoción y un puntaje.\n",
    "\n",
    "Utilizado en los clasificadores: `Anger`, `Fear`, `Joy`, `Sadness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Emoticons(BaseEstimator, TransformerMixin):\n",
    "    # largo = 1\n",
    "    def fun(self, tweet):\n",
    "        happy_faces=tweet.count(':)') + tweet.count(':D') + tweet.count('c:')\n",
    "        sad_faces=tweet.count(':(') + tweet.count(':c')\n",
    "        return [happy_faces*10,sad_faces*10]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(self.fun(tweet))\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features implementadas pero no utilizadas.\n",
    "\n",
    "#### CountLength\n",
    "Cuenta la cantidad de carácteres del Tweet. Se retiró dado a que confunde a todos\n",
    "los estimadores y no daba buenos resultados en los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CountLength(BaseEstimator, TransformerMixin):\n",
    "    # largo = 1\n",
    "    def get_relevant_chars(self, tweet):\n",
    "        num_chars = len(tweet)\n",
    "        return [num_chars]\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        chars = []\n",
    "        for tweet in X:\n",
    "            chars.append(self.get_relevant_chars(tweet))\n",
    "        return np.array(chars)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### NullFeature\n",
    "Debido a un error de Features, dado que se le daba una misma instancia de feature\n",
    "a los 4 pipelines, al crear la submission el programa se caía. Este feature fue una\n",
    "solución temporal pero definitivamente un síntoma del problema subyacente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NullFeature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        a_list = []\n",
    "        for tweet in X:\n",
    "            a_list.append(np.zeros(self.dim))\n",
    "        return a_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Algoritmos\n",
    "\n",
    "De los algoritmos de clasificación se decidió utilizar Regresión Logística, este es un algoritmo en que se hace una regresion en base a los datos de entrenamiento usando una transformacion lineal.\n",
    "Se decidió utilizar éste dado que es un estimador\n",
    "que es ideal para problemas de clasificación, dado que modela probabilidades, como el que se tratando aquí, dentro de las opciones\n",
    "internas de este estimador, se decidió utilizar la opción de multi_class `multinomial`, dado que el\n",
    "`one_vs_rest` se desbalancea dado que compara una clase con el resto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def estimator():\n",
    "    return LogisticRegression(max_iter=3000000, multi_class=\"multinomial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Métricas de Evaluación\n",
    "\n",
    "Las métricas utlizadas en la competencia para la evaluación de los clasificadores implementados son:\n",
    "\n",
    "- AUC: El AUC (Area Under the Curve), es una métrica que calcula el área de la curva ROC. La curva ROC, es una curva que\n",
    "compara la tasa falsos positivos contra la tasa verdaderos positivos a lo largo de los diferentes thresholds de una curva\n",
    "de probabilidades de un clasificador determinado.\n",
    "\n",
    "- Kappa: El coeficiente kappa de Cohen es una métrica que establece qué tan certero es el clasificador con los resultados\n",
    "esperados teniendo en cuenta la posibilidad de que las predicciones acertadas pudieron haber sido por mero azar.\n",
    "\n",
    "- Accuracy: El Accuracy mide la proporción de aciertos del clasificador de forma simple, contando la cantidad de clases\n",
    "bien predichas versus la cantidad de predicciones realizadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:20.604066Z",
     "start_time": "2020-04-07T15:44:20.589106Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SMWRq5nPvKeA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Estas funciones están a cargo de evaluar los resultados de la tarea. No deberían cambiarlas.\n",
    "\n",
    "def auc_score(test_set, predicted_set):\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array(\n",
    "        [prediction[1] for prediction in predicted_set])\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
    "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
    "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
    "    auc_high = roc_auc_score(high_test, high_predicted)\n",
    "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(low_test, low_predicted)\n",
    "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
    "             high_test.sum() * auc_high) / (\n",
    "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
    "    return auc_w\n",
    "\n",
    "\n",
    "def evaulate(predicted_probabilities, y_test, labels, dataset_name):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador.\n",
    "    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n",
    "    predicted_labels = [\n",
    "        labels[np.argmax(item)] for item in predicted_probabilities\n",
    "    ]\n",
    "    print('Confusion Matrix for {}:\\n'.format(dataset_name))\n",
    "    print(\n",
    "        confusion_matrix(y_test,\n",
    "                         predicted_labels,\n",
    "                         labels=['low', 'medium', 'high']))\n",
    "\n",
    "    print('\\nClassification Report:\\n')\n",
    "    print(\n",
    "        classification_report(y_test,\n",
    "                              predicted_labels,\n",
    "                              labels=['low', 'medium', 'high']))\n",
    "    # Reorder predicted probabilities array.\n",
    "    labels = labels.tolist()\n",
    "    predicted_probabilities = predicted_probabilities[:, [\n",
    "        labels.index('low'),\n",
    "        labels.index('medium'),\n",
    "        labels.index('high')\n",
    "    ]]\n",
    "    print(dataset_name, end='\\t')\n",
    "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
    "    print(\"Scores:\\n\\nAUC: \", auc, end='\\t')\n",
    "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "    print(\"Kappa:\", kappa, end='\\t')\n",
    "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print('------------------------------------------------------\\n')\n",
    "    return np.array([auc, kappa, accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimentos\n",
    "\n",
    "Para los experimentos y el entrenamiento se decidió utilizar undersampling, dado que la clase mayoritaria es el doble de las otras clases.\n",
    "\n",
    "Para la validación interna, cada prueba (run) obtiene el mismo conjunto del dataset reducido, el cual\n",
    "se clasifica para obtener los aumentos o bajas en las métricas dado algún cambio, se eligió una semilla específica\n",
    "para que ésta partición sea constante, sin embargo ésta partición no se revisó de ninguna forma para mejorar el clasificador.\n",
    "\n",
    "Para los primeros dos envíos de la competencia , los resultados fueron increíblemente anómalos, con\n",
    "resultados pobres a lo largo de todos las métricas salvo para `sadness`.\n",
    "\n",
    "Esto hizo aparecer un error de programación, que era que se estaba utilizando el mismo estimador para\n",
    "todos los pipelines de los otros clasifcadores, por lo que se entrenaba con los datos del último pipeline\n",
    "que era exactamente la métrica que no estaba tan afectada `sadness`.\n",
    "\n",
    "Otro error de programación que incluso contribuyó a la creación del feature `NullFeature` era que se\n",
    "utilizaba la misma instancia de `CountVectorizer` para entrenar los datos, lo que traía inconsistencias\n",
    "sobre la cantidad de features de cada uno de los pipelines a la hora de evaluar el conjunto target.\n",
    "\n",
    "Antes de realizar un submission más se corrigió un pequeño error en `SentimentLexicon`, éste consistía\n",
    "en que antes de realizar la tokenización, se eliminaban todos los `#` lo que producía que no se contabilizan\n",
    "la puntuación extra de los `hashtags`. Una vez corregido y haber comparado resultados, había un cambio\n",
    "de performance en los clasificadores: Todos los clasificadores salvo `sadness` empeoraban en sus métricas,\n",
    "por lo que se agregó el atributo `hashtag_scoring` a dicha clase.\n",
    "\n",
    "Ya resueltos estos problemas, se envió un nuevo submission. La mejora fue evidente, de los últimos\n",
    "puestos se subió considerablemente.\n",
    "\n",
    "En las pruebas internas de esa submission lograron los siguientes estadísticas:\n",
    "\n",
    "| - |AUC|Kappa|Accuracy|\n",
    "|----|----|----|-----|\n",
    "|Anger|0.748|0.383 | 0.59\n",
    "| Fear| 0.743|0.341 | 0.561\n",
    "| Joy|0.769\t|0.404| 0.603\n",
    "| Sadness|0.723|0.311|0.544\n",
    "|Average|0.746\t| 0.36| 0.575\n",
    "\n",
    "Posteriormente y siguiendo el argumento de `hastag_scoring` en `SentimentLexicon` se hizo\n",
    "mismo razonamiento en `MoodScore`, acción que impactaba negativamente en `joy` y `angry`, por lo\n",
    "que se desactivó en dichos casos.\n",
    "\n",
    "Este cambio mejoró los puntajes de `fear` y `sadness` a (y tambien en consecuencia):\n",
    "\n",
    "| - |AUC|Kappa|Accuracy|\n",
    "|----|----|----|-----|\n",
    "|Fear| 0.743$\\to$ 0.734|0.341 $\\to$0.35| 0.561$\\to$ 0.568\n",
    "|Sadness|0.723$\\to$ 0.718|0.311$\\to$0.334|0.544$\\to$ 0.559\n",
    "|Average|0.746$\\to$  0.742|0.36$\\to$  0.371| 0.575$\\to$  0.582\n",
    "\n",
    "Posteriormente se realizaron pruebas, sacando features para determinar si éstos confundían al\n",
    "clasificador.\n",
    "\n",
    "\n",
    "\n",
    "Para `joy`: Se eliminó `UpperLetters`\n",
    "Para `angry`: Se eliminó `CharCount` que contaba la cantidad de `'` (quotes) y la cantidad de emojis utilizados. Tambien\n",
    "se arregló el `CharCount` que contaba las palabras `rage` en vez de `fuck` (que era el propósito original).\n",
    "Para `sad`: Se eliminó `LowerCount`.\n",
    "\n",
    "\n",
    "Las estadísticas mejoraron a:\n",
    "\n",
    "| - |AUC|Kappa|Accuracy|\n",
    "|----|----|----|-----|\n",
    "|Anger|0.748 $\\to$ 0.743|0.383 $\\to$ 0.411 | 0.59 $\\to$ 0.609\n",
    "|Fear| 0.734|0.35\t| 0.568\n",
    "| Joy|0.769\t|0.404| 0.603\n",
    "|Sadness|0.718$\\to$ 0.725|0.334$\\to$0.328|0.559$\\to$ 0.564\n",
    "|Average|0.743$\\to$  0.743|0.371$\\to$  0.373| 0.584\n",
    "\n",
    "Para finalizar se experimentó utilizando `mark_negation` en el `n-gram` para ver si los resultados mejoraban:\n",
    "Mejoró las estadísticas para `fear` y `sadness`:\n",
    "\n",
    "| - |AUC|Kappa|Accuracy|\n",
    "|----|----|----|-----|\n",
    "|Fear| 0.734|0.35 $\\to$ 0.362| 0.568 $\\to$ 0.575\n",
    "|Sadness|0.725$\\to$0.718|0.328$\\to$0.342|0.584$\\to$ 0.564"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline ####\n",
    "\n",
    "Se definieron los siguientes pipelines a cada uno de los clasificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sad_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([\n",
    "                                    # Primary\n",
    "                                    ('n-gram', n_gram_feature()),\n",
    "                                    ('word_embeddings', WordEmbeddings(model)),\n",
    "                                    ('sentiment',SentimentLexicon(hashtag_scoring=True)),\n",
    "                                    ('sentiment_score',  MoodScore()),\n",
    "                                    ('emoji_score', EmojiScore()),\n",
    "                                    ('emoticons',Emoticons()),\n",
    "                                    # Secondary\n",
    "                                    ('emoji_count',EmojiCount()),\n",
    "                                    ('sad_count', CharsCount('sad')),\n",
    "                                    ('depression_count', CharsCount('depress')),\n",
    "                                    ('anxiety_count', CharsCount('anxi')),\n",
    "                                    ('feel_count', CharsCount('feel')),\n",
    "                                    ('!_count', CharsCount('!')),\n",
    "                                    ('gloom_count', CharsCount('gloo')),\n",
    "                                    ('.._count', CharsCount(\"..\")),\n",
    "                                    ])), ('clf', estimator())])\n",
    "\n",
    "def angry_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([\n",
    "                                    # Primary\n",
    "                                    ('n-gram', n_gram_feature_neg()),\n",
    "                                    ('word_embeddings', WordEmbeddings(model)),\n",
    "                                    ('sentiment',SentimentLexicon()),\n",
    "                                    ('sentiment_score',  MoodScore(hashtag_scoring=True)),\n",
    "                                    ('emoji_score', EmojiScore()),\n",
    "                                    ('emoticons',Emoticons()),\n",
    "                                    # Secondary\n",
    "                                    ('curse_words',CurseWords()),\n",
    "                                    ('angry_count', CharsCount('angry')),\n",
    "                                    ('fuck_count', CharsCount('fuck')),\n",
    "                                    ('#_count', CharsCount('#')),\n",
    "                                    ('!_count', CharsCount('!')),\n",
    "                                    ('*_count', CharsCount('*')),\n",
    "                                    ])), ('clf', estimator())])\n",
    "    \n",
    "def fear_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([\n",
    "                                    # Primary\n",
    "                                    ('n-gram', n_gram_feature()),\n",
    "                                    ('word_embeddings', WordEmbeddings(model)),\n",
    "                                    ('sentiment',SentimentLexicon()),\n",
    "                                    ('sentiment_score',  MoodScore()),\n",
    "                                    ('emoji_score', EmojiScore()),\n",
    "                                    ('emoticons',Emoticons()),\n",
    "                                    # Secondary\n",
    "                                    ('lower_count', LowerLetters()),\n",
    "                                    ('curse_words',CurseWords()),\n",
    "                                    ('terror_count', CharsCount(\"terr\")),\n",
    "                                    ('.._count', CharsCount(\"..\")),\n",
    "                                    ('feel_count', CharsCount(\"feel\")),\n",
    "                                    ('panic_count', CharsCount('panic')),\n",
    "                                    ('anxiety_count', CharsCount('anxi')),\n",
    "                                    ('nervous_count', CharsCount('nerv')),\n",
    "                                    ])), ('clf', estimator())])\n",
    "def joy_pipeline():\n",
    "    return Pipeline([('features',\n",
    "                      FeatureUnion([\n",
    "                                    # Primary\n",
    "                                    ('n-gram', n_gram_feature_neg()),\n",
    "                                    ('word_embeddings', WordEmbeddings(model)),\n",
    "                                    ('sentiment',SentimentLexicon()),\n",
    "                                    ('sentiment_score',  MoodScore(hashtag_scoring=True)),\n",
    "                                    ('emoji_score', EmojiScore()),\n",
    "                                    ('emoticons',Emoticons()),\n",
    "                                    # Secondary\n",
    "                                    ('emoji_count',EmojiCount()),\n",
    "                                    ('love_count', CharsCount(\"lov\")),\n",
    "                                    ('happy_count', CharsCount(\"happy\")),\n",
    "                                    ('joy_count', CharsCount('joy')),\n",
    "                                    ('smile_count', CharsCount('smil')),\n",
    "                                    ('heart_count', CharsCount('❤')),\n",
    "                                    ('!_count', CharsCount('!')),\n",
    "                                    ('fun', CharsCount('fun')),\n",
    "                                    ('laugh_count', CharsCount('laugh')),\n",
    "                                    ])), ('clf', estimator())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ejecutar el pipeline para algun data-set\n",
    "def run(dataset, dataset_name, pipeline):\n",
    "    \"\"\"Creamos el pipeline y luego lo ejecutamos el pipeline sobre un dataset. \n",
    "    Retorna el modelo ya entrenado mas sus labels asociadas y los scores obtenidos al evaluarlo.\"\"\"\n",
    "\n",
    "    # Dividimos el dataset en train y test.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset.tweet,\n",
    "        dataset.sentiment_intensity,\n",
    "        shuffle=True,\n",
    "        random_state=500,\n",
    "        test_size=0.33)\n",
    "\n",
    "    # Entrenamos el clasificador (Ejecuta el entrenamiento sobre todo el pipeline)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predecimos las probabilidades de intensidad de cada elemento del set de prueba.\n",
    "    predicted_probabilities = pipeline.predict_proba(X_test)\n",
    "\n",
    "    # Obtenemos el orden de las clases aprendidas.\n",
    "    learned_labels = pipeline.classes_\n",
    "\n",
    "    # Evaluamos:\n",
    "    scores = evaulate(predicted_probabilities, y_test, learned_labels, dataset_name)\n",
    "    return pipeline, learned_labels, scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for anger:\n",
      "\n",
      "[[35 16  2]\n",
      " [18 20  9]\n",
      " [11  7 43]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.55      0.66      0.60        53\n",
      "      medium       0.47      0.43      0.44        47\n",
      "        high       0.80      0.70      0.75        61\n",
      "\n",
      "    accuracy                           0.61       161\n",
      "   macro avg       0.60      0.60      0.60       161\n",
      "weighted avg       0.62      0.61      0.61       161\n",
      "\n",
      "anger\tScores:\n",
      "\n",
      "AUC:  0.743\tKappa: 0.411\tAccuracy: 0.609\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelines = {'anger':angry_pipeline(), 'fear':fear_pipeline(), 'joy':joy_pipeline(), 'sadness':sad_pipeline()}\n",
    "\n",
    "# Get clasif/labels/scores\n",
    "classifiers = []\n",
    "learned_labels_array = []\n",
    "scores_array = []\n",
    "\n",
    "for dataset_name, dataset in train.items():\n",
    "\n",
    "    # creamos el pipeline\n",
    "    pipeline = pipelines.get(dataset_name)\n",
    "\n",
    "    # ejecutamos el pipeline sobre el dataset\n",
    "    classifier, learned_labels, scores = run(df_resampled.get(dataset_name), dataset_name, pipeline)\n",
    "\n",
    "    # guardamos el clasificador entrenado (en realidad es el pipeline ya entrenado...)\n",
    "    classifiers.append(classifier)\n",
    "\n",
    "    # guardamos las labels aprendidas por el clasificador\n",
    "    learned_labels_array.append(learned_labels)\n",
    "\n",
    "    # guardamos los scores obtenidos\n",
    "    scores_array.append(scores)\n",
    "\n",
    "\n",
    "# print avg scores\n",
    "print(\n",
    "    \"Average scores:\\n\\n\",\n",
    "    \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\"\n",
    "    .format(*np.array(scores_array).mean(axis=0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir los target set y crear la submission\n",
    "\n",
    "Aquí predecimos los target set usando los clasificadores creados y creamos los archivos de las submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_target(dataset, classifier, labels):\n",
    "    # Predecir las probabilidades de intensidad de cada elemento del target set.\n",
    "    predicted = pd.DataFrame(classifier.predict_proba(dataset.tweet), columns=labels)\n",
    "    # Agregar ids\n",
    "    predicted['id'] = dataset.id.values\n",
    "    # Reordenar las columnas\n",
    "    predicted = predicted[['id', 'low', 'medium', 'high']]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_target = {}\n",
    "\n",
    "# Crear carpeta ./predictions\n",
    "if not os.path.exists('./predictions'):\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "else:\n",
    "    # Eliminar predicciones anteriores:\n",
    "    shutil.rmtree('./predictions')\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "# por cada target set:\n",
    "for idx, key in enumerate(target):\n",
    "    # Predecirlo\n",
    "    predicted_target[key] = predict_target(target[key], classifiers[idx],\n",
    "                                           learned_labels_array[idx])\n",
    "    # Guardar predicciones en archivos separados. \n",
    "    predicted_target[key].to_csv('./predictions/{}-pred.txt'.format(key),\n",
    "                                 sep='\\t',\n",
    "                                 header=False,\n",
    "                                 index=False)\n",
    "\n",
    "# Crear archivo zip\n",
    "a = shutil.make_archive('predictions', 'zip', './predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Conclusiones\n",
    "Desarrollar features para el análisis de intensidad en tweets, permite el estudio profundo de cómo se expresan los seres humanos, problema principal de este curso.\n",
    "Dados los resultados de los experimentos se concluye que en efecto hay patrones que afectan la intensidad de la emoción al clasificar, que bien pueden ser los emojis utilizados, o bien ciertas palabras en especifico, como también el uso de caracteres especiales. Tambien se puede notar del efecto que tienen los hashtag para medir la intensidad de las emociones, dado que al darles más peso en los Features los puntajes mejoraron considerablemente. En general al darle más peso a estas features cuando no eran igual a cero, mejoraban considerablemente los puntajes, por lo que se puede concluir que afectan de gran manera la intensidad de la emocion.\n",
    "\n",
    "Otra cosa que tambien se puede notar luego de hacer varios experimentos, es que todas las emociones tienen sus propias caracteristicas y es distinto clasificar intensidad en alegria que en tristeza o miedo, por lo que cada emoción requiere su propio analisis.\n",
    "\n",
    "Dado los problemas que ocurrieron en los primeros experimentos, tambien es de notar que la forma en que el clasificador está programado afecta el resultados de los experimentos, puesto que en nuestro caso al escribir el programa en los primero experimentos nos daba resultados enormemente distintos a la de los siguientes experimentos incluso con las mismas features, por lo que es importante considerar la forma en que están escritos los programas.\n",
    "\n",
    "Tambien es importante saber como se utilizan los paquetes dado que los clasificadores que escribimos depende de su buen funcionamiento y buen uso, dado que afectan el puntaje del clasificador.\n",
    "\n",
    "Ahora en base a los resultados de las clasificaciones se aprecia que las metricas con la intensidad media son más bajas que la  misma metrica con la intensidad baja o alta en todas las emociones. Para mejorar esto en el futuro se está pensando en utilizar un clasificador que diferencia la intensidad media de las otras intensidades, para luego clasificar estos datos con las intensidades bajas o altas. Tambien se está pensando en considerar otros clasificadores que no habian sido considerados hasta ahora.\n",
    "Si se mejorase con la intensidad media el proyecto podria utilizarse para medir intensidad de emociones en distintos eventos, como en un terremoto o en un atentado. Como tambien ver la opinion publica de ciertas temas en especificos como en la politica."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "t1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
